{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Samsung 2.7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergeyMalyshevsky/Samsung-Neural-Network-Course/blob/master/Samsung_2_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2efPLVVuiSyg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d7e77a57-e7be-4341-8a1c-d65d7c9b39b5"
      },
      "source": [
        "import torch\n",
        "\n",
        "# создаем тензор\n",
        "# атрибут requeres_grad=True превращает тензор-константу в тензор переменную\n",
        "# и сообщает, что данный тензор является переменной, \n",
        "# по которой нужно будет считать градиенты\n",
        "x = torch.tensor([\n",
        "    [1., 2., 3., 4.],\n",
        "    [5., 6., 7., 8.],\n",
        "    [9., 10., 11., 12.]\n",
        "], requires_grad=True)\n",
        "\n",
        "# переносим вычисления на GPU если он есть\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() \n",
        "                      else 'cpu')\n",
        "x = x.to(device)\n",
        "\n",
        "# определяем функцию\n",
        "function = 10 * (x ** 2).sum()\n",
        "\n",
        "# вызываем backward, результат записывается в свойство x.grad\n",
        "function.backward()\n",
        "\n",
        "print(x.grad, '<- gradient')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 20.,  40.,  60.,  80.],\n",
            "        [100., 120., 140., 160.],\n",
            "        [180., 200., 220., 240.]]) <- gradient\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZn70xyYjdvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1b9af0ba-88a3-43e9-c60a-7b9d4f0b8c45"
      },
      "source": [
        "# показать последнюю функцию\n",
        "print(function.grad_fn)\n",
        "# показать предпоследнюю функцию\n",
        "print(function.grad_fn.next_functions[0][0])\n",
        "# показать предпредпоследнюю функцию\n",
        "print(function.grad_fn.next_functions[0][0].next_functions[0][0])\n",
        "# показать предпредпредпоследнюю функцию\n",
        "print(function.grad_fn.next_functions[0][0].next_functions[0][0]\n",
        "      .next_functions[0][0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MulBackward0 object at 0x7f6baa2380f0>\n",
            "<SumBackward0 object at 0x7f6b5e7d0358>\n",
            "<PowBackward0 object at 0x7f6baa2380f0>\n",
            "<AccumulateGrad object at 0x7f6baaa9fe80>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Awt1g7h_l0px",
        "colab_type": "text"
      },
      "source": [
        "Задание"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrA1f0tZld6p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0859ef98-b495-45b8-ec74-79899ea36c50"
      },
      "source": [
        "w = torch.tensor([[5., 10.], [1., 2.]], requires_grad=True)\n",
        "\n",
        "# определяем функцию\n",
        "function = torch.log(torch.log((w + 7))).prod()\n",
        "\n",
        "# вызываем backward, результат записывается в свойство x.grad\n",
        "function.backward()\n",
        "\n",
        "print(w.grad, '<- gradient')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0201, 0.0109],\n",
            "        [0.0449, 0.0351]]) <- gradient\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-eMhsGZmRJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.data -= 0.001 * x.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvySt6CLnaC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a7a281b9-0492-49c3-d2bd-e47e6bd664c7"
      },
      "source": [
        "# нижнее подчеркивание на конце метода означает, что он будет применен к тому \n",
        "# объекту над которым выполняется(inplace операции)\n",
        "\n",
        "# метод zero_() обнуляет градиенты\n",
        "x.grad.zero_()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ2gUQ9xpk5D",
        "colab_type": "text"
      },
      "source": [
        "**Создание функций для градиентного спуска**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FlboubincuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor([8., 8.], requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.SGD([x], lr=0.001)\n",
        "\n",
        "def function_parabola(variable):\n",
        "  return 10 * (variable ** 2).sum()\n",
        "\n",
        "def make_gradient_step(loss_function, variable):\n",
        "  loss_function_result = loss_function(variable)\n",
        "  loss_function_result.backward()\n",
        "  #variable.data -= 0.001 * variable.grad\n",
        "  optimizer.step()\n",
        "  #variable.grad.zero_()\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "for i in range(500):\n",
        "  make_gradient_step(function_parabola, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enzRbnbgqewz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "f0993efa-d87a-4f59-e774-3ce0eeb4c6e2"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "show_contours(function_parabola)\n",
        "plt.scatter(np.array(var_history)[:,0], np.array(var_history)[:, 1], s=10,\n",
        "           c='r')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-98adb1cbb299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshow_contours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_parabola\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m plt.scatter(np.array(var_history)[:,0], np.array(var_history)[:, 1], s=10,\n\u001b[1;32m      5\u001b[0m            c='r')\n",
            "\u001b[0;31mNameError\u001b[0m: name 'show_contours' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L02LH1eOsIQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}